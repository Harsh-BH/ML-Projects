{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:\n",
    "\n",
    "z = w*x+b\n",
    "\n",
    "but it dosent give value between 0 and 1 so for that sigmoid function is used:\n",
    "\n",
    "p = 1/(1+e^-z)\n",
    "\n",
    "it give probability of binary classes.\n",
    "\n",
    "if p>=0.5:\n",
    "    y_pred=1\n",
    "else:\n",
    "y_pred=0\n",
    "\n",
    "# To calculate error in logistic regression , first loss is calculated:\n",
    "  loss = -y*log(p) - (1-y)*log(1-p)\n",
    "\n",
    "# then error:\n",
    " error = 1/n * sum(loss)\n",
    "\n",
    "# to calculate w,b gradient descent is used:\n",
    " w = w - alpha * dw\n",
    " b = b- alpha *db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature_1  Feature_2   Feature_3  Target\n",
      "0   94.870985  88.239326  101.497093       0\n",
      "1   97.684482  84.837474   90.892151       0\n",
      "2   94.648343  77.467282   87.646104       0\n",
      "3   94.635471  85.327735   99.851568       0\n",
      "4  104.397011  84.097116   98.211326       0\n",
      "    Feature_1  Feature_2  Feature_3  Target\n",
      "0   97.533783  88.329103  98.191966       0\n",
      "1  102.838058  78.783627  90.867559       0\n",
      "2   95.155724  86.679155  94.861119       0\n",
      "3  102.838797  87.504581  99.622361       0\n",
      "4   99.238078  86.704614  91.685225       0\n"
     ]
    }
   ],
   "source": [
    "data1_train = pd.read_csv('data1_train.csv')\n",
    "data1_test = pd.read_csv('data1_test.csv')\n",
    "\n",
    "print(data1_train.head())\n",
    "print(data1_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature_1   Feature_2  Target\n",
      "0   8.160646   88.799326       0\n",
      "1  31.149536  102.335826       0\n",
      "2  13.103383   92.902908       0\n",
      "3  15.950445   77.412565       0\n",
      "4  35.856965   94.441550       0\n",
      "   Feature_1  Feature_2  Target\n",
      "0  48.489576  81.609641       0\n",
      "1  26.069706  89.783100       0\n",
      "2  31.967447  88.005024       0\n",
      "3  44.957613  91.219129       0\n",
      "4  27.681870  87.381969       0\n"
     ]
    }
   ],
   "source": [
    "data2_train = pd.read_csv('data2_train.csv')\n",
    "data2_test = pd.read_csv('data2_test.csv')\n",
    "\n",
    "print(data2_train.head())\n",
    "print(data2_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize_data(train_data, test_data):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(train_data.iloc[:, :-1].values)\n",
    "\n",
    "    y_train = train_data.iloc[:, -1].values\n",
    "\n",
    "    X_test = scaler.transform(test_data.iloc[:, :-1].values)\n",
    "\n",
    "    y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train1, y_train1, X_test1, y_test1 = normalize_data(data1_train, data1_test)\n",
    "\n",
    "X_train2, y_train2, X_test2, y_test2 = normalize_data(data2_train, data2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X, y, learning_rate=0.01, num_iterations=1000):\n",
    "    m, n = X.shape\n",
    "    w = np.zeros(n)\n",
    "    b = 0\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "      \n",
    "        z = np.dot(X, w) + b\n",
    "        \n",
    "        p = sigmoid(z)\n",
    "      \n",
    "        loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n",
    "        \n",
    "        error = np.mean(loss)\n",
    "        \n",
    "        dw = (1 / m) * np.dot(X.T, (p - y))\n",
    "\n",
    "        db = (1 / m) * np.sum(p - y)\n",
    "        \n",
    "        w -= learning_rate * dw\n",
    "\n",
    "        b -= learning_rate * db\n",
    "\n",
    "    return w,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta, bias):\n",
    "    z = np.dot(X, theta) + bias\n",
    "    p = sigmoid(z)\n",
    "    return [1 if i >= 0.5 else 0 for i in p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_31624\\3663828769.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_31624\\3663828769.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_31624\\1226599341.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "def evaluate(X_train, y_train, X_test, y_test, w, b):\n",
    "\n",
    "    y_train_pred = predict(X_train, w, b)\n",
    "\n",
    "    y_test_pred = predict(X_test, w, b)\n",
    "\n",
    "    train_accuracy = np.mean(y_train_pred == y_train) * 100\n",
    "\n",
    "    test_accuracy = np.mean(y_test_pred == y_test) * 100\n",
    "\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "w, b = train_logistic_regression(X_train1, y_train1, learning_rate=0.01, num_iterations=1000000)\n",
    "\n",
    "train_accuracy, test_accuracy = evaluate(X_train1, y_train1, X_test1, y_test1, w, b)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}%')\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_31624\\3663828769.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_31624\\3663828769.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_31624\\1226599341.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.001, 'num_iterations': 500}\n",
      "Best Training Accuracy: 54.87%\n"
     ]
    }
   ],
   "source": [
    "def grid_search(X_train, y_train, learning_rates, num_iterations):\n",
    "\n",
    "    best_accuracy = 0\n",
    "\n",
    "    best_params = {'learning_rate': None, 'num_iterations': None}\n",
    "\n",
    "    for lr in learning_rates:\n",
    "\n",
    "        for iters in num_iterations:\n",
    "\n",
    "            w, b = train_logistic_regression(X_train, y_train, learning_rate=lr, num_iterations=iters)\n",
    "\n",
    "            train_accuracy, _ = evaluate(X_train, y_train, X_train, y_train, w, b)\n",
    "\n",
    "            if train_accuracy > best_accuracy:\n",
    "\n",
    "                best_accuracy = train_accuracy\n",
    "\n",
    "                best_params['learning_rate'] = lr\n",
    "\n",
    "                best_params['num_iterations'] = iters\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "num_iterations = [500, 1000, 2000]\n",
    "\n",
    "params,accuracy = grid_search(X_train1, y_train1, learning_rates, num_iterations)\n",
    "print(f'Best Parameters: {params}')\n",
    "print(f'Best Training Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn Training Accuracy: 98.00%\n",
      "Scikit-Learn Test Accuracy: 97.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compare_with_sklearn(X_train, y_train, X_test, y_test, best_params):\n",
    "    \n",
    "    model= LogisticRegression(max_iter=best_params['num_iterations'])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = model.predict(X_train)\n",
    "\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, pred_train) * 100\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, pred_test) * 100\n",
    "\n",
    "    return accuracy_test, accuracy_train\n",
    "\n",
    "train_accuracy_sklearn, test_accuracy_sklearn = compare_with_sklearn(X_train1, y_train1, X_test1, y_test1, params)\n",
    "\n",
    "print(f'Scikit-Learn Training Accuracy: {train_accuracy_sklearn:.2f}%')\n",
    "print(f'Scikit-Learn Test Accuracy: {test_accuracy_sklearn:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
