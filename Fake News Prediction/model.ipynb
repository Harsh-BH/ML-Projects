{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"K:\\ML-Projects\\Fake News Prediction\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing null values with empty string\n",
    "df = df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content\"] = df.title + \" \" + df.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        House Dem Aide: We Didn’t Even See Comey’s Let...\n",
       "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
       "2        Why the Truth Might Get You Fired Consortiumne...\n",
       "3        15 Civilians Killed In Single US Airstrike Hav...\n",
       "4        Iranian woman jailed for fictional unpublished...\n",
       "                               ...                        \n",
       "20795    Rapper T.I.: Trump a ’Poster Child For White S...\n",
       "20796    N.F.L. Playoffs: Schedule, Matchups and Odds -...\n",
       "20797    Macy’s Is Said to Receive Takeover Approach by...\n",
       "20798    NATO, Russia To Hold Parallel Exercises In Bal...\n",
       "20799              What Keeps the F-35 Alive David Swanson\n",
       "Name: content, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('label',axis=1)\n",
    "y=df.label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming:\n",
    "\n",
    "Stemming is the process of reducting a word to its root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem  = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "  stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "  stemmed_content = stemmed_content.lower()\n",
    "  stemmed_content = stemmed_content.split()\n",
    "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "  stemmed_content = ' '.join(stemmed_content)\n",
    "  return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content = df.content.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        hous dem aid even see comey letter jason chaff...\n",
       "1        flynn hillari clinton big woman campu breitbar...\n",
       "2                   truth might get fire consortiumnew com\n",
       "3        civilian kill singl us airstrik identifi jessi...\n",
       "4        iranian woman jail fiction unpublish stori wom...\n",
       "                               ...                        \n",
       "20795    rapper trump poster child white supremaci jero...\n",
       "20796    n f l playoff schedul matchup odd new york tim...\n",
       "20797    maci said receiv takeov approach hudson bay ne...\n",
       "20798    nato russia hold parallel exercis balkan alex ...\n",
       "20799                            keep f aliv david swanson\n",
       "Name: content, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.content.values\n",
    "\n",
    "y= df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting textual data to numerical data\n",
    "vect = TfidfVectorizer()\n",
    "vect.fit(x)\n",
    "\n",
    "x= vect.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 22799)\t0.18006628418201243\n",
      "  (0, 22093)\t0.2657547217665701\n",
      "  (0, 21737)\t0.3484096682234656\n",
      "  (0, 18603)\t0.22538156291100417\n",
      "  (0, 12368)\t0.3024246896410992\n",
      "  (0, 11983)\t0.24883580084136206\n",
      "  (0, 10863)\t0.20615338107008116\n",
      "  (0, 10760)\t0.15318017966160952\n",
      "  (0, 9846)\t0.18448937077363603\n",
      "  (0, 7052)\t0.2304743493560024\n",
      "  (0, 5649)\t0.2467735137762447\n",
      "  (0, 5302)\t0.25028059659920077\n",
      "  (0, 5010)\t0.2993451324113331\n",
      "  (0, 4013)\t0.20531564772935784\n",
      "  (0, 3362)\t0.3057979629237607\n",
      "  (0, 418)\t0.2635419649523391\n",
      "  (1, 23191)\t0.2966210296019264\n",
      "  (1, 14607)\t0.15862263711495958\n",
      "  (1, 9592)\t0.18787145765749733\n",
      "  (1, 7895)\t0.7045992054867243\n",
      "  (1, 4971)\t0.2624012615566619\n",
      "  (1, 3806)\t0.19024289659874757\n",
      "  (1, 3013)\t0.37751839443307017\n",
      "  (1, 2585)\t0.15310531118537438\n",
      "  (1, 2051)\t0.2899843833664323\n",
      "  :\t:\n",
      "  (20797, 11627)\t0.21659193986049335\n",
      "  (20797, 10714)\t0.12516633187998083\n",
      "  (20797, 9887)\t0.20792477683235197\n",
      "  (20797, 5061)\t0.20389975589596085\n",
      "  (20797, 2901)\t0.14456424605079038\n",
      "  (20797, 1780)\t0.31989436828531154\n",
      "  (20797, 984)\t0.29969673985755974\n",
      "  (20797, 746)\t0.0987242947097849\n",
      "  (20797, 59)\t0.28338371263237516\n",
      "  (20798, 21221)\t0.11012879273571911\n",
      "  (20798, 18067)\t0.21203810857283628\n",
      "  (20798, 15084)\t0.4330367731657488\n",
      "  (20798, 13942)\t0.302697668091279\n",
      "  (20798, 10221)\t0.12372667259693101\n",
      "  (20798, 9687)\t0.3360628776269571\n",
      "  (20798, 7154)\t0.4330367731657488\n",
      "  (20798, 1577)\t0.4330367731657488\n",
      "  (20798, 837)\t0.2956214782753605\n",
      "  (20798, 526)\t0.27034138578025346\n",
      "  (20799, 22936)\t0.3036883879058238\n",
      "  (20799, 21006)\t0.11435323534322306\n",
      "  (20799, 20546)\t0.5069780866279595\n",
      "  (20799, 11265)\t0.5156967065416901\n",
      "  (20799, 5039)\t0.3386739535864246\n",
      "  (20799, 559)\t0.5069780866279595\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "pred =model.predict(x_test)\n",
    "score= accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of test set is:0.9774038461538461\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy of test set is:{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train set is:0.9873798076923077\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred2 =model.predict(x_train)\n",
    "score2= accuracy_score(pred2,y_train)\n",
    "print(f\"accuracy of train set is:{score2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a predcitive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "news is fake\n"
     ]
    }
   ],
   "source": [
    "x_new= x_test[0]\n",
    "\n",
    "\n",
    "prediction = model.predict(x_test[0])\n",
    "print(prediction)\n",
    "\n",
    "if(prediction[0]==0):\n",
    "  print(\"news is real\")\n",
    "else :\n",
    "  print(\"news is fake\")\n",
    "  \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
